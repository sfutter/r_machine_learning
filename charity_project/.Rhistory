par(mfrow=c(2,2))
boxplot(DAMT~HOME, data=charity, col='lightgray',main="Charity Data - HOME",
xlab="Home Owner (HOME)",
ylab="Donation Amount (in $)")
boxplot(DAMT~HINC, data=charity, col='lightgray',main="Charity Data - HINC",
xlab="Household Income (HINC)",
ylab="Donation Amount (in $)")
boxplot(DAMT~RFA_97, data=charity, col='lightgray',main="Charity Data - RFA_97",
xlab="Donor's RFA status as of 1997 Promo date (RFA_97)",
ylab="Donation Amount (in $)")
boxplot(DAMT~RFA_96, data=charity, col='lightgray',main="Charity Data - RFA_96",
xlab="Donor's RFA status as of 1996 Promo date (RFA_96)",
ylab="Donation Amount (in $)")
df1 = charity[,-6]  #remove HINC
names(df1)
par(mfrow=c(2,2))
df1$LOG_MAXRAMNT = log(df1$MAXRAMNT)
plot(df1$MAXRAMNT,df1$DAMT, main='MAXRAMNT')
plot(df1$LOG_MAXRAMNT,df1$DAMT, main='Log(MAXRAMNT)')
df1$LOG_RAMNTALL = log(df1$RAMNTALL)
plot(df1$RAMNTALL,df1$DAMT, main='RAMNTALL')
plot(df1$LOG_RAMNTALL,df1$DAMT, main='Log(RAMNTALL)')
#df1$RECENCY_97   = substr(RFA_97,1,1)   #removed as only 1 factor found.
df1$FREQUENCY_97 = substr(RFA_97,2,2)
df1$AMOUNT_97    = substr(RFA_97,3,3)
df1$RECENCY_96   = substr(RFA_96,1,1)
df1$FREQUENCY_96 = substr(RFA_96,2,2)
df1$AMOUNT_96    = substr(RFA_96,3,3)
names(df1)
df1 = df1[,c(-1,-2,-19,-20)]  # remove ID, DONR, RFA_96, and RFA_97 in addition to HINC removed previously
names(df1)
dim(df1) # 3684 x 23
names(df1)
smp.size = floor(0.75 * nrow(df1))
set.seed(1)
train = sample(seq_len(nrow(df1)), size = smp.size)
test = -train
ch.train = df1[train,]
ch.test = df1[-train,]
dim(ch.train)
summary(ch.train)
dim(ch.test)
summary(ch.test)
fit1 = lm(DAMT~LASTGIFT,ch.train)
summary(fit1)
plot(fit1)
df1$FREQUENCY_97 = factor(df1$FREQUENCY_97)
df1$AMOUNT_97    = factor(df1$AMOUNT_97)
df1$RECENCY_96   = factor(df1$RECENCY_96)
df1$FREQUENCY_96 = factor(df1$FREQUENCY_96)
df1$AMOUNT_96    = factor(df1$AMOUNT_96)
str(df1)
library(leaps)
fit2=regsubsets(DAMT~., data=ch.train)
summary(fit2)
fit2.summary = summary(fit2)
plot(fit2.summary$adj.r.squared, xlab='Number of Variables', ylab='Adjusted R Squared', type='l')
plot(fit2, scale='Cp')
plot(fit2, scale='Cp')
par(mfrow=c(1,1))
plot(fit2, scale='Cp')
par(mfrow=c(1,1))
plot(fit2, scale='adjr2')
setwd('/Users/stevenfutter/Dropbox/NU/MACHINE_LEARNING/charity_project')
charity = read.csv('projectDataPart1.csv', header=T, na.strings="NA",
stringsAsFactors = TRUE,
colClasses=c("DONR"="factor", "HOME"="factor","HINC"="factor"))
# set up $ expansion
attach(charity)
# check that column types are set up correctly
str(charity)
# confirm size of data table
dim(charity) # 3684 21
# take a peek at the data
head(charity)
library(Hmisc)
Hmisc::describe(charity)
library(plyr)
library(psych)
multi.hist(charity[,sapply(charity, is.numeric)])
df = charity[,-1]   # remove ID variable
names(df)
# create new data.frame (df.num) with numeric and integer values only to plot correlations
df.num = df[,sapply(df, class) %in% c("numeric", "integer") ]
# calculate the correlations between each variable and DAMT
apply(df.num,2, function(col)cor(col, df.num$DAMT))
# build scatterplots between numeric variables
par(mfrow=c(1,3))
plot(df.num$LASTGIFT, df.num$DAMT)
plot(df.num$MAXRAMNT, df.num$DAMT)
plot(df.num$RAMNTALL, df.num$DAMT)
par(mfrow=c(2,2))
boxplot(DAMT~HOME, data=charity, col='lightgray',main="Charity Data - HOME",
xlab="Home Owner (HOME)",
ylab="Donation Amount (in $)")
boxplot(DAMT~HINC, data=charity, col='lightgray',main="Charity Data - HINC",
xlab="Household Income (HINC)",
ylab="Donation Amount (in $)")
boxplot(DAMT~RFA_97, data=charity, col='lightgray',main="Charity Data - RFA_97",
xlab="Donor's RFA status as of 1997 Promo date (RFA_97)",
ylab="Donation Amount (in $)")
boxplot(DAMT~RFA_96, data=charity, col='lightgray',main="Charity Data - RFA_96",
xlab="Donor's RFA status as of 1996 Promo date (RFA_96)",
ylab="Donation Amount (in $)")
df1 = charity[,-6]  #remove HINC
names(df1)
par(mfrow=c(2,2))
df1$LOG_MAXRAMNT = log(df1$MAXRAMNT)
plot(df1$MAXRAMNT,df1$DAMT, main='MAXRAMNT')
plot(df1$LOG_MAXRAMNT,df1$DAMT, main='Log(MAXRAMNT)')
df1$LOG_RAMNTALL = log(df1$RAMNTALL)
plot(df1$RAMNTALL,df1$DAMT, main='RAMNTALL')
plot(df1$LOG_RAMNTALL,df1$DAMT, main='Log(RAMNTALL)')
#df1$RECENCY_97   = substr(RFA_97,1,1)   #removed as only 1 factor found.
df1$FREQUENCY_97 = substr(RFA_97,2,2)
df1$AMOUNT_97    = substr(RFA_97,3,3)
df1$RECENCY_96   = substr(RFA_96,1,1)
df1$FREQUENCY_96 = substr(RFA_96,2,2)
df1$AMOUNT_96    = substr(RFA_96,3,3)
names(df1)
df1 = df1[,c(-1,-2,-19,-20)]  # remove ID, DONR, RFA_96, and RFA_97 in addition to HINC removed previously
names(df1)
dim(df1) # 3684 x 23
names(df1)
smp.size = floor(0.75 * nrow(df1))
set.seed(1)
train = sample(seq_len(nrow(df1)), size = smp.size)
test = -train
ch.train = df1[train,]
ch.test = df1[-train,]
dim(ch.train)
summary(ch.train)
dim(ch.test)
summary(ch.test)
fit1 = lm(DAMT~LASTGIFT,ch.train)
summary(fit1)
plot(fit1)
df1$FREQUENCY_97 = factor(df1$FREQUENCY_97)
df1$AMOUNT_97    = factor(df1$AMOUNT_97)
df1$RECENCY_96   = factor(df1$RECENCY_96)
df1$FREQUENCY_96 = factor(df1$FREQUENCY_96)
df1$AMOUNT_96    = factor(df1$AMOUNT_96)
str(df1)
library(leaps)
fit2=regsubsets(DAMT~., data=ch.train)
summary(fit2)
setwd('/Users/stevenfutter/Dropbox/NU/MACHINE_LEARNING/charity_project')
charity = read.csv('projectDataPart1.csv', header=T, na.strings="NA",
stringsAsFactors = TRUE,
colClasses=c("DONR"="factor", "HOME"="factor","HINC"="factor"))
# set up $ expansion
attach(charity)
# check that column types are set up correctly
str(charity)
# confirm size of data table
dim(charity) # 3684 21
# take a peek at the data
head(charity)
library(Hmisc)
Hmisc::describe(charity)
library(plyr)
library(psych)
multi.hist(charity[,sapply(charity, is.numeric)])
df = charity[,-1]   # remove ID variable
names(df)
# create new data.frame (df.num) with numeric and integer values only to plot correlations
df.num = df[,sapply(df, class) %in% c("numeric", "integer") ]
# calculate the correlations between each variable and DAMT
apply(df.num,2, function(col)cor(col, df.num$DAMT))
# build scatterplots between numeric variables
par(mfrow=c(1,3))
plot(df.num$LASTGIFT, df.num$DAMT)
plot(df.num$MAXRAMNT, df.num$DAMT)
plot(df.num$RAMNTALL, df.num$DAMT)
par(mfrow=c(2,2))
boxplot(DAMT~HOME, data=charity, col='lightgray',main="Charity Data - HOME",
xlab="Home Owner (HOME)",
ylab="Donation Amount (in $)")
boxplot(DAMT~HINC, data=charity, col='lightgray',main="Charity Data - HINC",
xlab="Household Income (HINC)",
ylab="Donation Amount (in $)")
boxplot(DAMT~RFA_97, data=charity, col='lightgray',main="Charity Data - RFA_97",
xlab="Donor's RFA status as of 1997 Promo date (RFA_97)",
ylab="Donation Amount (in $)")
boxplot(DAMT~RFA_96, data=charity, col='lightgray',main="Charity Data - RFA_96",
xlab="Donor's RFA status as of 1996 Promo date (RFA_96)",
ylab="Donation Amount (in $)")
df1 = charity[,-6]  #remove HINC
names(df1)
par(mfrow=c(2,2))
df1$LOG_MAXRAMNT = log(df1$MAXRAMNT)
plot(df1$MAXRAMNT,df1$DAMT, main='MAXRAMNT')
plot(df1$LOG_MAXRAMNT,df1$DAMT, main='Log(MAXRAMNT)')
df1$LOG_RAMNTALL = log(df1$RAMNTALL)
plot(df1$RAMNTALL,df1$DAMT, main='RAMNTALL')
plot(df1$LOG_RAMNTALL,df1$DAMT, main='Log(RAMNTALL)')
#df1$RECENCY_97   = substr(RFA_97,1,1)   #removed as only 1 factor found.
df1$FREQUENCY_97 = substr(RFA_97,2,2)
df1$AMOUNT_97    = substr(RFA_97,3,3)
df1$RECENCY_96   = substr(RFA_96,1,1)
df1$FREQUENCY_96 = substr(RFA_96,2,2)
df1$AMOUNT_96    = substr(RFA_96,3,3)
names(df1)
df1 = df1[,c(-1,-2,-19,-20)]  # remove ID, DONR, RFA_96, and RFA_97 in addition to HINC removed previously
names(df1)
dim(df1) # 3684 x 23
names(df1)
smp.size = floor(0.75 * nrow(df1))
set.seed(1)
train = sample(seq_len(nrow(df1)), size = smp.size)
test = -train
ch.train = df1[train,]
ch.test = df1[-train,]
dim(ch.train)
summary(ch.train)
dim(ch.test)
summary(ch.test)
fit1 = lm(DAMT~LASTGIFT,ch.train)
summary(fit1)
plot(fit1)
df1$FREQUENCY_97 = factor(df1$FREQUENCY_97)
df1$AMOUNT_97    = factor(df1$AMOUNT_97)
df1$RECENCY_96   = factor(df1$RECENCY_96)
df1$FREQUENCY_96 = factor(df1$FREQUENCY_96)
df1$AMOUNT_96    = factor(df1$AMOUNT_96)
str(df1)
library(leaps)
fit2=regsubsets(DAMT~., data=ch.train)
summary(fit2)
library(glmnet)
x = model.matrix(DAMT~., df1)
y=df1$DAMT
grid=10^seq(10,-2,length=100)
fit3 = glmnet(x[train,], y[train], alpha=1, lambda=grid)  # alpha=1 is the LASSO model
summary(fit3)
library(glmnet)
x = model.matrix(DAMT~., df1)
y=df1$DAMT
grid=10^seq(10,-2,length=100)
fit3 = glmnet(x[train,], y[train], alpha=1, lambda=grid)  # alpha=1 is the LASSO model
library(glmnet)
x = model.matrix(DAMT~., df1)
y=df1$DAMT
grid=10^seq(10,-2,length=100)
fit3 = glmnet(x[train,], y[train], alpha=1, lambda=grid)  # alpha=1 is the LASSO model
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
plot(cv.out)
bestlam=cv.out$lambda.min                          # 0.6740771 lambda is the best lambda value
bestlam
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
plot(cv.out)
bestlam=cv.out$lambda.min                          # 0.6740771 lambda is the best lambda value
bestlam
bestlam
# install.packages('tree')
# The tree library is used to construct classification and regression trees.
library(tree)
fit4=tree(DAMT~.,df1,subset=train) # fitting regression tree to training set.
summary(fit4)
par(mfrow=c(1,1))
plot(fit4)
text(fit4, pretty=0)
lasso.coef=predict(fit3,type='coefficients',s=bestlam)
lasso.coef                       # 3 out of 10 coef's are non-zero
lasso.coef[lasso.coef!=0]
mean((DAMT-predict(fit1, df1))[train]^2)      # MSE Training Set = 65.18256
mean((DAMT-predict(fit1, df1))[test]^2)       # MSE Test Set     = 79.24383
mean((DAMT-predict(fit2, df1))[train]^2)      # MSE Training Set = 59.64491
mean((DAMT-predict(fit1, df1))[train]^2)      # MSE Training Set = 65.18256
mean((DAMT-predict(fit1, df1))[test]^2)       # MSE Test Set     = 79.24383
mean((DAMT-predict(fit2, df1))[train]^2)      # MSE Training Set = 59.64491
library(leaps)
fit2=regsubsets(DAMT~., data=ch.train)
fit2=lm(DAMT~HOME+NUMPROM+RAMNTALL+NGIFTALL+LASTGIFT+LOG_MAXRAMNT+AMOUNT_97+AMOUNT_97+FREQUENCY_96, data=ch.train)
mean((DAMT-predict(fit2, df1))[train]^2)      # MSE Training Set = 59.64491
mean((DAMT-predict(fit2, df1))[test]^2)       # MSE Test Set     = 73.80784
fit2=lm(DAMT~HOME+GENDER+RAMNTALL+NGIFTALL+LASTGIFT+LOG_MAXRAMNT+AMOUNT_97F+AMOUNT_97+FREQUENCY_96, data=ch.train)
setwd('/Users/stevenfutter/Dropbox/NU/MACHINE_LEARNING/charity_project')
charity = read.csv('projectDataPart1.csv', header=T, na.strings="NA",
stringsAsFactors = TRUE,
colClasses=c("DONR"="factor", "HOME"="factor","HINC"="factor"))
# set up $ expansion
attach(charity)
# check that column types are set up correctly
str(charity)
# confirm size of data table
dim(charity) # 3684 21
# take a peek at the data
head(charity)
library(Hmisc)
Hmisc::describe(charity)
library(plyr)
library(psych)
multi.hist(charity[,sapply(charity, is.numeric)])
df = charity[,-1]   # remove ID variable
names(df)
# create new data.frame (df.num) with numeric and integer values only to plot correlations
df.num = df[,sapply(df, class) %in% c("numeric", "integer") ]
# calculate the correlations between each variable and DAMT
apply(df.num,2, function(col)cor(col, df.num$DAMT))
# build scatterplots between numeric variables
par(mfrow=c(1,3))
plot(df.num$LASTGIFT, df.num$DAMT)
plot(df.num$MAXRAMNT, df.num$DAMT)
plot(df.num$RAMNTALL, df.num$DAMT)
par(mfrow=c(2,2))
boxplot(DAMT~HOME, data=charity, col='lightgray',main="Charity Data - HOME",
xlab="Home Owner (HOME)",
ylab="Donation Amount (in $)")
boxplot(DAMT~HINC, data=charity, col='lightgray',main="Charity Data - HINC",
xlab="Household Income (HINC)",
ylab="Donation Amount (in $)")
boxplot(DAMT~RFA_97, data=charity, col='lightgray',main="Charity Data - RFA_97",
xlab="Donor's RFA status as of 1997 Promo date (RFA_97)",
ylab="Donation Amount (in $)")
boxplot(DAMT~RFA_96, data=charity, col='lightgray',main="Charity Data - RFA_96",
xlab="Donor's RFA status as of 1996 Promo date (RFA_96)",
ylab="Donation Amount (in $)")
df1 = charity[,-6]  #remove HINC
names(df1)
par(mfrow=c(2,2))
df1$LOG_MAXRAMNT = log(df1$MAXRAMNT)
plot(df1$MAXRAMNT,df1$DAMT, main='MAXRAMNT')
plot(df1$LOG_MAXRAMNT,df1$DAMT, main='Log(MAXRAMNT)')
df1$LOG_RAMNTALL = log(df1$RAMNTALL)
plot(df1$RAMNTALL,df1$DAMT, main='RAMNTALL')
plot(df1$LOG_RAMNTALL,df1$DAMT, main='Log(RAMNTALL)')
#df1$RECENCY_97   = substr(RFA_97,1,1)   #removed as only 1 factor found.
df1$FREQUENCY_97 = substr(RFA_97,2,2)
df1$AMOUNT_97    = substr(RFA_97,3,3)
df1$RECENCY_96   = substr(RFA_96,1,1)
df1$FREQUENCY_96 = substr(RFA_96,2,2)
df1$AMOUNT_96    = substr(RFA_96,3,3)
names(df1)
df1 = df1[,c(-1,-2,-19,-20)]  # remove ID, DONR, RFA_96, and RFA_97 in addition to HINC removed previously
names(df1)
dim(df1) # 3684 x 23
names(df1)
smp.size = floor(0.75 * nrow(df1))
set.seed(1)
train = sample(seq_len(nrow(df1)), size = smp.size)
test = -train
ch.train = df1[train,]
ch.test = df1[-train,]
dim(ch.train)
summary(ch.train)
dim(ch.test)
summary(ch.test)
fit1 = lm(DAMT~LASTGIFT,ch.train)
summary(fit1)
plot(fit1)
df1$FREQUENCY_97 = factor(df1$FREQUENCY_97)
df1$AMOUNT_97    = factor(df1$AMOUNT_97)
df1$RECENCY_96   = factor(df1$RECENCY_96)
df1$FREQUENCY_96 = factor(df1$FREQUENCY_96)
df1$AMOUNT_96    = factor(df1$AMOUNT_96)
str(df1)
library(leaps)
fit2=regsubsets(DAMT~., data=ch.train)
summary(fit2)
library(glmnet)
x = model.matrix(DAMT~., df1)
y=df1$DAMT
grid=10^seq(10,-2,length=100)
fit3 = glmnet(x[train,], y[train], alpha=1, lambda=grid)  # alpha=1 is the LASSO model
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam                       # 0.6740771 lambda is the best lambda value. We will use this later on to calculate the training and test data MSE's.
lasso.coef=predict(fit3,type='coefficients',s=bestlam)
lasso.coef                       # 3 out of 10 coef's are non-zero
lasso.coef[lasso.coef!=0]
# install.packages('tree')
# The tree library is used to construct classification and regression trees.
library(tree)
fit4=tree(DAMT~.,df1,subset=train) # fitting regression tree to training set.
summary(fit4)
par(mfrow=c(1,1))
plot(fit4)
text(fit4, pretty=0)
mean((DAMT-predict(fit1, df1))[train]^2)      # MSE Training Set = 65.18256
mean((DAMT-predict(fit1, df1))[test]^2)       # MSE Test Set     = 79.24383
fit2=lm(DAMT~HOME+GENDER+RAMNTALL+NGIFTALL+LASTGIFT+LOG_MAXRAMNT+AMOUNT_97+AMOUNT_97+FREQUENCY_96, data=ch.train)
mean((DAMT-predict(fit2, df1))[train]^2)      # MSE Training Set = 59.64491
mean((DAMT-predict(fit2, df1))[test]^2)       # MSE Test Set     = 73.80784
predict.regsubsets=function(object, newdata, id, ...){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object, id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
y.test=y[test]
y.train=y[train]
lasso.pred=predict(fit3,s=bestlam,newx=x[train,])
mean((lasso.pred-y.train)^2)                        # 61.35197 is train MSE
lasso.pred=predict(fit3,s=bestlam,newx=x[test,])
mean((lasso.pred-y.test)^2)                         # 74.24213 is the MSE
yhat=predict(fit4,newdata=df1[train,])
mean((yhat-y.train)^2)          # 63.87194
yhat=predict(fit4,newdata=df1[test,])
mean((yhat-y.test)^2)          # 75.07405
mean((DAMT-predict(fit1, df1))[train]^2)      # MSE Training Set = 65.18256
mean((DAMT-predict(fit1, df1))[test]^2)       # MSE Test Set     = 79.24383
fit1.train.mse = mean((DAMT-predict(fit1, df1))[train]^2)
fit1.test.mse  = mean((DAMT-predict(fit1, df1))[test]^2)
fit2=lm(DAMT~HOME+GENDER+RAMNTALL+NGIFTALL+LASTGIFT+LOG_MAXRAMNT+AMOUNT_97+AMOUNT_97+FREQUENCY_96, data=ch.train)
mean((DAMT-predict(fit2, df1))[train]^2)      # MSE Training Set = 59.37364
mean((DAMT-predict(fit2, df1))[test]^2)       # MSE Test Set     = 73.79594
fit2.train.mse = mean((DAMT-predict(fit2, df1))[train]^2)
fit2.test.mse  = mean((DAMT-predict(fit2, df1))[test]^2)
predict.regsubsets=function(object, newdata, id, ...){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object, id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
y.test=y[test]
y.train=y[train]
lasso.pred=predict(fit3,s=bestlam,newx=x[train,])
mean((lasso.pred-y.train)^2)                        # 61.35197 is train MSE
lasso.pred=predict(fit3,s=bestlam,newx=x[test,])
mean((lasso.pred-y.test)^2)                         # 74.24213 is the MSE
fit3.train.mse = mean((lasso.pred-y.train)^2)
predict.regsubsets=function(object, newdata, id, ...){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object, id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
y.test=y[test]
y.train=y[train]
lasso.pred=predict(fit3,s=bestlam,newx=x[train,])
mean((lasso.pred-y.train)^2)                        # 61.35197 is train MSE
lasso.pred=predict(fit3,s=bestlam,newx=x[test,])
mean((lasso.pred-y.test)^2)                         # 74.24213 is the MSE
#fit3.train.mse = mean((lasso.pred-y.train)^2)
#fit3.test.mse  = mean((lasso.pred-y.test)^2)
predict.regsubsets=function(object, newdata, id, ...){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object, id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
y.test=y[test]
y.train=y[train]
lasso.pred=predict(fit3,s=bestlam,newx=x[train,])
mean((lasso.pred-y.train)^2)                        # 61.35197 is train MSE
lasso.pred=predict(fit3,s=bestlam,newx=x[test,])
mean((lasso.pred-y.test)^2)                         # 74.24213 is the MSE
fit3.train.mse = mean((lasso.pred-y.train)^2)
predict.regsubsets=function(object, newdata, id, ...){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object, id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
y.test=y[test]
y.train=y[train]
lasso.pred=predict(fit3,s=bestlam,newx=x[train,])
mean((lasso.pred-y.train)^2)                        # 61.35197 is train MSE
fit3.train.mse = mean((lasso.pred-y.train)^2)
lasso.pred=predict(fit3,s=bestlam,newx=x[test,])
mean((lasso.pred-y.test)^2)                         # 74.24213 is the MSE
fit3.test.mse  = mean((lasso.pred-y.test)^2)
yhat=predict(fit4,newdata=df1[train,])
mean((yhat-y.train)^2)          # 63.87194
fit4.train.mse = mean((yhat-y.train)^2)
yhat=predict(fit4,newdata=df1[test,])
mean((yhat-y.test)^2)          # 75.07405
fit4.test.mse  = mean((yhat-y.test)^2)
source('~/Dropbox/NU/MACHINE_LEARNING/charity_project/steven_futter_charity_problem_1.R', echo=TRUE)
data.frame(1,2,3,4)
col1 = c('Model 1', 1,2)
col2 = c('Model 2', 3,4)
cbind(col1,col2)
hbind(col1,col2)
cbind(col1,col2)
cbind(col1,col2, header=F)
Model     = c('Model 1','Model 2', 'Model 3', 'Model 4')
Train_MSE = c(fit1.train.mse, fit2.train.mse, fit3.train.mse, fit4.train.mse)
Test_MSE  = c(fit1.test.mse, fit2.test.mse, fit3.test.mse, fit4.test.mse)
cbind(Model, Train_MSE, Test_MSE)
Model     = c('Model 1','Model 2', 'Model 3', 'Model 4')
Train_MSE = c(round(fit1.train.mse,3), fit2.train.mse, fit3.train.mse, fit4.train.mse)
Test_MSE  = c(fit1.test.mse, fit2.test.mse, fit3.test.mse, fit4.test.mse)
cbind(Model, Train_MSE, Test_MSE)
Model     = c('Model 1','Model 2', 'Model 3', 'Model 4')
Train_MSE = c(round(fit1.train.mse,3), round(fit2.train.mse,3), round(fit3.train.mse,3), round(fit4.train.mse,3))
Test_MSE  = c(round(fit1.test.mse,3), round(fit2.test.mse,3), round(fit3.test.mse,3), round(fit4.test.mse,3))
cbind(Model, Train_MSE, Test_MSE)
Model     = c('Model 1','Model 2', 'Model 3', 'Model 4')
Train_MSE = c(round(fit1.train.mse,3), round(fit2.train.mse,3), round(fit3.train.mse,3), round(fit4.train.mse,3))
Test_MSE  = c(round(fit1.test.mse,3), round(fit2.test.mse,3), round(fit3.test.mse,3), round(fit4.test.mse,3))
table = cbind(Model, Train_MSE, Test_MSE)
table
Model     = c('Model 1','Model 2', 'Model 3', 'Model 4')
Train_MSE = c(round(fit1.train.mse,3), round(fit2.train.mse,3), round(fit3.train.mse,3), round(fit4.train.mse,3))
Test_MSE  = c(round(fit1.test.mse,3), round(fit2.test.mse,3), round(fit3.test.mse,3), round(fit4.test.mse,3))
table = cbind(Model, Train_MSE, Test_MSE)
table
65.183-79.244
59.374-73.796
61.352-74.242
63.872-75.074
